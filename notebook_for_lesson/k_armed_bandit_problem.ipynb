{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-armed Bandit Problem\n",
    "The K-armed bandit problem is a classic problem in reinforcement learning and decision theory. It is a simplified model of the exploration-exploitation trade-off, where an agent must choose between different actions to maximize its total reward over time.\n",
    "### Introduction\n",
    "In the K-armed bandit problem, an agent is faced with [K different actions (or arms)] to choose from. Each action provides a reward drawn from a probability distribution specific to that action. The goal of the agent is to maximize the total reward over a series of trials by choosing the best actions.\n",
    "### Define K-armed\n",
    "1. **K**    : The number of different actions (or arms) available to the agent.\n",
    "2. **Arms** : Each arm represents a different action that the agent can take. Each arm has an associated reward distribution.\n",
    "---\n",
    "\n",
    "### How it work \n",
    "1. **Initialization** : The agent starts with no knowledge about the reward distributions of the arms.\n",
    "2. **Action selection**: At each time step, the agent selects one of the K arms to pull based on a strategy or policy.\n",
    "3. **Reward Observation**:The agent observes the reward obtained from the selected arm.\n",
    "4. **Update**: The agent updates its knowledge about the reward distribution of the selected arm based on the observed reward.\n",
    "5. **Repeat**: Steps 2-4 are repeated for a specified number of trials or until a stopping condition is met.\n",
    "\n",
    "# Exploration vs Exploitation\n",
    "The main challenge in the K-armed bandit problem is balancing:\n",
    "- **Exploration** : Trying out different arms to learn their reward distributions.\n",
    "- **Exploitation**: Selection the arm that is currently estimated to provide the highest reward.\n",
    "---\n",
    "# Example code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rewards obtained: 9571.506450417282\n",
      "Estimated action values: [ 0.68105166  0.80288199  0.56973275 -0.02326379  1.00141859]\n",
      "Number of times each action was selected: [ 216.  376.  227.  196. 8985.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class EpsilonGreedyAgent:\n",
    "    def __init__(self, num_actions, epsilon=0.1):\n",
    "        self.num_actions = num_actions  # Số hành động (tay cầm của máy đánh bạc)\n",
    "        self.epsilon = epsilon          # Xác suất chọn hành động ngẫu nhiên (exploration)\n",
    "        self.action_values = np.zeros(num_actions)  # Giá trị ước lượng của mỗi hành động\n",
    "        self.action_counts = np.zeros(num_actions)  # Số lần mỗi hành động được chọn\n",
    "    def select_action(self):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Chọn ngẫu nhiên (exploration)\n",
    "            action = np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            # Chọn hành động có giá trị kỳ vọng cao nhất (exploitation)\n",
    "            action = np.argmax(self.action_values)\n",
    "        return action\n",
    "    def update_value(self, action, reward):\n",
    "        self.action_counts[action] += 1  # Tăng số lần hành động được chọn\n",
    "        self.action_values[action] += (1 / self.action_counts[action]) * (reward - self.action_values[action])\n",
    "class MultiArmedBandit:\n",
    "    def __init__(self, num_arms):\n",
    "        self.num_arms = num_arms\n",
    "        self.true_action_values = np.random.normal(0, 1, num_arms)\n",
    "    def get_reward(self, action):\n",
    "        return np.random.normal(self.true_action_values[action], 1)\n",
    "num_arms = 5 # Số tay cầm\n",
    "num_steps = 10000  # Số lần thực hiện\n",
    "agent = EpsilonGreedyAgent(num_arms)  # Khởi tạo tác nhân epsilon-greedy\n",
    "bandit = MultiArmedBandit(num_arms)  # Khởi tạo môi trường\n",
    "total_rewards = 0 # Tổng phần thưởng\n",
    "for step in range(num_steps):\n",
    "    action = agent.select_action()            # Tác nhân chọn hành động\n",
    "    reward = bandit.get_reward(action)        # Nhận phần thưởng từ môi trường\n",
    "    agent.update_value(action, reward)       # Cập nhật giá trị kỳ vọng\n",
    "    total_rewards += reward                   # Cộng dồn phần thưởng\n",
    "print(\"Total rewards obtained:\", total_rewards)\n",
    "print(\"Estimated action values:\", agent.action_values)\n",
    "print(\"Number of times each action was selected:\", agent.action_counts)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
